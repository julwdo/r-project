---
title: "Predicting Customer Default in Banking"
author: "Julia Maria Wdowinska"
output:
  html_document:
    toc: TRUE
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The goal of this project is to predict customer default in the banking sector by leveraging a dataset containing information on 700 past and 150 prospective bank customers. The dataset encompasses various features such as age, education level, employment duration, address duration, income, debt-related metrics, and the binary default status (Yes or No).

The project aims to explore the relationships between these features and customer defaults, employing both data visualization and statistical modeling techniques. Through the analysis, I intend to provide insights into the factors influencing default rates and develop predictive models to enhance our understanding and forecasting capabilities in the banking context.

# Data Preparation

## Loading Required Libraries

```{r, results = 'hide', warning = FALSE, message = FALSE}
library(foreign)
library(dplyr)
library(ggplot2)
library(plotly)
library(ggcorrplot)
library(xgboost)
library(margins)
```

## Loading the Data

```{r, warning = FALSE, message = FALSE}
path <- "D:/Studies/Materials/Second-cycle/I year/I semester/Coding for DS and DM/R/r-project"

data <- read.spss(paste0(path, "/bankloan.sav"), to.data.frame = TRUE) %>%
  select(-matches("preddef"))
head(data)
```
The `bankloan.sav` dataset, provided by IBM, contains information on 700 past and 150 prospective bank customers.

The variables of interest include:

`age`: Age in years,\
`ed`: Level of education,\
`employ`: Number of years with the current employer,\
`address`: Number of years at the current address,\
`income`: Household income in thousands,\
`debtinc`: Debt-to-income ratio in percentage,\
`creddebt`: Credit card debt in thousands,\
`othdebt`: Other debt in thousands,\
`default`: Default status ("Yes" or "No").

## Data Structure

```{r, warning = FALSE, message = FALSE}
str(data)
```

The dataset contains 7 numeric and 2 factor variables.

## Summary Statistics

```{r, warning = FALSE, message = FALSE}
summary(data)
```

Customer age ranges from 20 to 56 years, with a mean of approximately 35.03 years. The majority (460) did not complete high school. Employment duration spans 0 to 33 years, averaging 8.566 years.

Address duration ranges from 0 to 34 years, with a mean of approximately 8.372 years. Income varies from \$13,000 to \$446,000, averaging \$46,680. Debt-to-income ratio ranges from 0.10% to 41.30%, with a mean of 10.17%. Credit card debt ranges from \$11.7 to \$20,561.3, with an average of \$1,576.8. Other debts range from \$45.58 to \$35,197.50, averaging $3,078.79.

Regarding default status, 517 customers have not defaulted, 183 have defaulted, and 150 missing values refer to prospective customers.

# Data Visualization

## Selected Density Plots

```{r, warning = FALSE, message = FALSE}
ggplotly(
  ggplot(data %>% filter(!is.na(default)), # Filter out prospective customers
         aes(x = age, fill = default)) +
    geom_density(alpha = 0.5) +
    labs(title = "Age Distribution by Default Status"))
```

```{r, warning = FALSE, message = FALSE}
ggplotly(
  ggplot(data %>% filter(!is.na(default)), # Filter out prospective customers
         aes(x = employ, fill = default)) +
    geom_density(alpha = 0.5) +
    labs(title = "Employment Duration Distribution by Default Status"))
```

```{r, warning = FALSE, message = FALSE}
ggplotly(
  ggplot(data %>% filter(!is.na(default)), # Filter out prospective customers
         aes(x = debtinc, fill = default)) +
    geom_density(alpha = 0.5) +
    labs(title = "Debt-to-Income Ratio Distribution by Default Status"))
```

```{r, warning = FALSE, message = FALSE}
ggplotly(
  ggplot(data %>% filter(!is.na(default)), # Filter out prospective customers
         aes(x = creddebt, fill = default)) +
    geom_density(alpha = 0.5) +
    labs(title = "Credit Card Debt Distribution by Default Status"))
```

The visual narrative conveyed by the plots suggests a compelling relationship between lower age and shorter tenure at the current employer, both seemingly linked to a higher likelihood of default. Conversely, a lower debt-to-income ratio emerges as a potential mitigating factor against default risk. Notably, credit card debt stands out as less pivotal and alone may not be a decisive factor in distinguishing between default and non-default cases.

## Correlation Heatmap

```{r, warning = FALSE, message = FALSE}
cormat <- cor(data %>%
                filter(!is.na(default)) %>% # Filter out prospective customers
                select_if(is.numeric)) # Consider only numeric variables
ggcorrplot(cormat, type = "lower", outline.color = "white", lab = TRUE) +
  ggtitle("Correlation Heatmap of Numeric Independent Variables")
```

The correlation heatmap among numeric independent variables shows modest associations (ranging from -0.03 to 0.63), with none reaching notably high levels. This suggests a lack of significant multicollinearity, supporting the decision to retain all variables for model estimation.

# Data Preparation for Estimation

## Recoding the Variables

```{r, warning = FALSE, message = FALSE}
data.1 <- data %>%
  mutate(
    ed_1 = as.numeric(ed == "Did not complete high school"),
    ed_2 = as.numeric(ed == "High school degree"),
    ed_3 = as.numeric(ed == "Some college"),
    ed_4 = as.numeric(ed == "College degree"),
    ed_5 = as.numeric(ed == "Post-undergraduate degree"),
    default_num = as.numeric(default == "Yes")
    )

data.2 <- data.1 %>%
  select(-ed, -ed_1, -default) %>% # Remove "ed_1" to avoid perfect multicollinearity
  filter(!is.na(default_num)) # Filter out prospective customers
head(data.2)
```

## Splitting the Data into Training and Test Set

```{r, warning = FALSE, message = FALSE}
set.seed(123)

indices <- sample(nrow(data.2), size = 0.7*nrow(data.2))

data.train <- data.2[indices, ]
data.test <- data.2[-indices, ]

print(paste0("Size of the training set: ", dim(data.train)[1]))
print(paste0("Size of the test set: ", dim(data.test)[1]))
```

# Estimating Logit Model Using Top-Down Approach

## Estimating the First Logit Model

```{r, warning = FALSE, message = FALSE}
fit.full <- glm(default_num ~ ., family = binomial(), data = data.train)
summary(fit.full)
```

Based on the current analysis, variables such as `age`, `income`, `debtinc`, `othdebt`, and certain education levels (`ed_3`, `ed_4`, `ed_5`) are not statistically significant at the 0.05 significance level. However, I believe that the variable `debtinc` is crucial in influencing a customer's ability to repay a loan. Consequently, the forthcoming logistic regression model will be estimated, excluding all variables deemed statistically insignificant, except for the variable `debtinc`.

## Estimating the Second Logit Model

```{r, warning = FALSE, message = FALSE}
fit.reduced <- glm(default_num ~ . - age - income - othdebt - ed_3 - ed_4 - ed_5,
                   family = binomial(), data = data.train)
summary(fit.reduced)

print(paste0("AIC for the First Logit Model: ", round(AIC(fit.full), 2)))
print(paste0("AIC for the Second Logit Model: ", round(AIC(fit.reduced), 2)))
```

The Akaike information criterion (AIC) for the reduced logistic regression model is lower, indicating that the model performs better with the exclusion of certain variables. Additionally, in this refined model, all variables demonstrate statistical significance at the 0.05 level.

# Training XGBoost (Extreme Gradient Boosting)

## Data Formatting for Estimation and Validation

```{r, warning = FALSE, message = FALSE}
X.train <- as.matrix(data.train %>% select(-default_num))
y.train <- data.train$default_num

d.train <- xgb.DMatrix(X.train, label = y.train)

X.test <- as.matrix(data.test %>% select(-default_num))
y.test <- data.test$default_num
```

## Specifying Parameters and Training the Model

```{r, warning = FALSE, message = FALSE}
params <- list(objective = "binary:logistic", eval_metric = "logloss")
xgb <- xgboost(params = params, data = d.train, nrounds = 50)
```

`objective = "binary:logistic"`: This sets the objective function for the XGBoost model to binary logistic regression, indicating that the model is being trained for binary classification (0 or 1 outcomes). `eval_metric = "logloss"`: This specifies the evaluation metric to be used during training. In this case, it is the log-loss, a common metric for classification problems. `nrounds = 50`: This parameter indicates the number of boosting rounds (iterations) for training. The model will be trained for 50 rounds.

# Evaluating Predictive Ability

## Creating Confusion Matrices (Test Set)

```{r, warning = FALSE, message = FALSE}
lr.pred <- predict(fit.reduced, data.test, type = "response")
xgb.pred <- predict(xgb, X.test)

lr.confmat <- table(true = y.test, pred = round(lr.pred))
xgb.confmat <- table(true = y.test, pred = round(xgb.pred))

print("Logit Model Confusion Matrix:")
print(lr.confmat)
print("XGBoost Confusion Matrix:")
print(xgb.confmat)
```

## Computing Accuracies (Test Set)

```{r, warning = FALSE, message = FALSE}
calc_accuracy <- function(confmat) {
  return(sum(diag(confmat))/sum(confmat))
}

acc <- sapply(list(lr.confmat, xgb.confmat), calc_accuracy)

print(paste0("Accuracy of the Logit Model: ", round(acc[1], 4)))
print(paste0("Accuracy of the XGBoost Model: ", round(acc[2], 4)))
```
The accuracy of the Logistic Regression model is reported as `r round(acc[1], 4)`, indicating that the model correctly predicted outcomes for approximately `r round(acc[1]*100, 2)`% of the instances in the test dataset. In comparison, the XGBoost model achieved an accuracy of `r round(acc[2], 4)`, suggesting it correctly predicted outcomes for approximately `r round(acc[2]*100, 2)`% of the instances, slightly lower than the Logit model.

Given the higher accuracy of the Logistic Regression model compared to XGBoost, the conclusion is to prefer the Logit model for making predictions on this particular dataset.

## Saving the Chosen Model to a File

```{r, warning = FALSE, message = FALSE}
saveRDS(fit.reduced, "fit.reduced.rds")
```

# Interpreting Estimation Results

## Computing Average Marginal Effects (AME)

```{r, warning = FALSE, message = FALSE}
AME <- summary(margins(glm(default_num ~ employ + address + debtinc + creddebt + ed_2,
                           family = binomial(), data = data.train)))
AME
```

Interpretations:

Each additional year of living at the current address *reduces* by `r round(abs(AME[1,2]), 4)` (on average) the probability that a given person will default on a loan.\
Each additional $1000 of credit card debt *increases* by `r round(abs(AME[2,2]), 4)` (on average) the probability that a given person will default on a loan.\
Each additional percentage point of debt to income ratio *increases* by `r round(abs(AME[3,2]), 4)` (on average) the probability that a given person will default on a loan.\
A person with a high school degree has a *higher* probability of defaulting on a loan compared to an individual who did not complete high school by `r round(abs(AME[4,2]), 4)` (on average).\
Each additional year of working with the current employer *reduces* by `r round(abs(AME[5,2]), 4)` (on average) the probability that a given person will default on a loan.

All interpretations are given under the *ceteris paribus* assumption.

## Computing Odds Ratio

```{r, warning = FALSE, message = FALSE}
oddsratio <- exp(coef(fit.reduced))
oddsratio
```

Interpretations:

Each additional year of working with the current employer *reduces* by `r round(abs((1-oddsratio["employ"])*100), 2)`% (on average) the chance that a given person will default on a loan.\
Each additional year of living at the current address *reduces* by `r round(abs((1-oddsratio["address"])*100), 2)`% (on average) the chance that a given person will default on a loan.\
Each additional percentage point of debt to income ratio *increases* by `r round(abs((1-oddsratio["debtinc"])*100), 2)`% (on average) the chance that a given person will default on a loan.\
Each additional $1000 of credit card debt *increases* by `r round(abs((1-oddsratio["creddebt"])*100), 2)`% (on average) the chance that a given person will default on a loan.\
A person with a high school degree has a *higher* chance of defaulting on a loan compared to an individual who did not complete high school by `r round(abs((1-oddsratio["ed_2"])*100), 2)`% (on average).

All interpretations are given under the *ceteris paribus* assumption.

# Forecasting Default of Prospective Customers

## Calculating Probabilities of Default for New Customers

```{r}
newdata <- data.1 %>%
  filter(is.na(default_num)) # Filter out past customers
predict(fit.reduced, newdata, type = "response")
```

# Final Remarks

My investigation into predicting customer default in the banking sector has provided valuable insights. Initially, visual cues suggested connections between lower age, shorter employment duration, and a higher likelihood of default, with debt-to-income ratio as a mitigating factor. While statistical analysis confirmed the importance of employment duration and debt-to-income ratio, it debunked the significance of age. Furthermore, it unveiled the importance of variables like credit card debt, years at the current address, and education level.

This emphasizes the shift from visual intuition to statistical rigor. While data visualization provides initial insights, statistical analysis plays a crucial role in navigating the complexities of predictive modeling.